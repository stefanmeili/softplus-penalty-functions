{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c24024",
   "metadata": {},
   "source": [
    "# Softplus Penalty Function Experiments\n",
    "**Stefan Meili<br>2021-09-07**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c889e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import os\n",
    "thread_count = len(os.sched_getaffinity(0))\n",
    "\n",
    "import time\n",
    "\n",
    "import secrets\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28623e",
   "metadata": {},
   "source": [
    "# Define Optimization Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc14ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Penalty function lookup dictionary\n",
    "#Return an approprate penalty function given type and constraint operator keys\n",
    "#penalty functions accept constraint error (x), and hardness parameter (alpha)\n",
    "penalty_functions = {\n",
    "    'algebraic':{\n",
    "        '<': lambda x, a: (np.sqrt(4 * a**2 + np.square(x)) + x)/2,\n",
    "        '=': lambda x, a: np.sqrt(4 * a**2 + np.square(x)),\n",
    "        '>': lambda x, a: (np.sqrt(4 * a**2 + np.square(x)) - x)/2\n",
    "    },\n",
    "    'algx':{\n",
    "        '<': lambda x, a: (np.sqrt(4 * a**2 + np.square(x)) + x)/2 + np.square(np.maximum(0,x)),\n",
    "        '=': lambda x, a: np.sqrt(4 * a**2 + np.square(x))+np.square(x),\n",
    "        '>': lambda x, a: (np.sqrt(4 * a**2 + np.square(x)) - x)/2 + np.square(np.maximum(0,-x))\n",
    "    },\n",
    "    'logistic':{\n",
    "        '<': lambda x, a: np.where(np.abs(x/a) < 1023, a*np.log2(1 + np.exp2(x/a)), np.maximum(0,x)),\n",
    "        '=': lambda x, a: np.where(np.abs(x/a) < 1023, 2 * a * np.log2(1 + np.exp2(x/a)) - x, np.maximum(0,x)),\n",
    "        '>': lambda x, a: np.where(np.abs(x/a) < 1023, a*np.log2(1 + np.exp2(-x/a)), np.maximum(0,x)),\n",
    "    },\n",
    "    'linear':{\n",
    "        '<': lambda x, a: np.maximum(0, x),\n",
    "        '=': lambda x, a: np.abs(x),\n",
    "        '>': lambda x, a: np.maximum(0, -x),\n",
    "    }\n",
    "}\n",
    "\n",
    "class Constraint:\n",
    "    def __init__(self, operator, target = 0, ptype = 'algebraic', sigma = 1, alpha = 1, beta = 1):\n",
    "        '''\n",
    "        Simple constraint container class that stores penalty function, target, and relevant parameters\n",
    "            operator = string operator. Must be in ['<', '=', '>']\n",
    "            target = float\n",
    "            ptype = string penalty function type. Must be in ['algebraic', 'algx', logistic', 'linear'] \n",
    "        '''\n",
    "        self.operator = operator\n",
    "        self.target = target\n",
    "        self.ptype = ptype\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.beta = beta\n",
    "        \n",
    "        if self.beta !=1: \n",
    "            self.penalty = lambda x: self.sigma * penalty_functions[self.ptype][self.operator](x, self.alpha)**self.beta\n",
    "        else:\n",
    "            self.penalty = lambda x: self.sigma * penalty_functions[self.ptype][self.operator](x, self.alpha)\n",
    "            \n",
    "    def __call__(self, value):\n",
    "        x = value - self.target\n",
    "        return self.penalty(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    '''\n",
    "    Simple problem container class that stores objective coefficients, projection, and combination method\n",
    "        o_coeffs = numpy float array with N coefficients for N dimensional problem\n",
    "        projection = a callable class that projects input vector x onto the constraint space where each row returned\n",
    "                     is a constraint\n",
    "        combine = string in [norm, sum, max, sum_square] that defines how constraints are combined\n",
    "    '''\n",
    "    def __init__(self, o_coeffs, projection, combine = 'norm', **kwargs):\n",
    "        self.o_coeffs = o_coeffs.reshape(1,-1)\n",
    "        self.n_dims = o_coeffs.shape[0]\n",
    "        \n",
    "        self.projection = projection\n",
    "        \n",
    "        if combine == 'norm': self.combine_fn = lambda y: np.linalg.norm(y, axis = 0)\n",
    "        elif combine == 'sum': self.combine_fn = lambda y: np.sum(y, axis = 0)\n",
    "        elif combine == 'max': self.combine_fn = lambda y: np.max(y, axis = 0)\n",
    "        elif combine == 'sum_square': self.combine_fn = lambda y: np.sum(np.square(y), axis = 0)\n",
    "        elif combine == 'norm2': self.combine_fn = lambda y: np.sqrt(\n",
    "            np.sum(np.square(y), axis = 0) + np.square(np.sum(y, axis = 0)))\n",
    "        else: raise Exception('Invalid combine option, must be [norm, sum, max, sum_square]')\n",
    "        \n",
    "        self.constraint = Constraint('<', **kwargs)\n",
    "    \n",
    "    def _objective(self, x):\n",
    "        #Return optimization objective\n",
    "        return np.sum(np.multiply(self.o_coeffs, x), axis = 1)\n",
    "    \n",
    "    def _penalty(self, x):\n",
    "        #Return penalty for constraint violations\n",
    "        x_ = x.reshape(-1, self.n_dims)\n",
    "        return self.combine_fn(self.constraint(self.projection(x_)))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        #Return constrained optimization objective function\n",
    "        return self._objective(x) + self._penalty(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27318821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_objective(n, max_grad = 5):\n",
    "    #Generate random linear objective coefficents with dimensions n and a specified maximum gradient\n",
    "    grad = np.random.uniform(low = 1e-2, high = max_grad)\n",
    "    u = np.random.uniform(low = -1, high = 1, size = n)\n",
    "    return u / np.linalg.norm(u) * grad, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Planes:\n",
    "    '''\n",
    "    hyperplane projection of x onto new constraint space defined by points and normals\n",
    "    '''\n",
    "    def __init__(self, points, normals):\n",
    "        self.points = points[:,np.newaxis,:]\n",
    "        self.normals = normals[:,np.newaxis,:]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return np.sum((x - self.points) * self.normals, axis = -1)\n",
    "\n",
    "def rand_shear_mat(n, max_shear = 2, n_shears = 1):\n",
    "    #Generate a random shearing matrix specifying dimensions n, maximum shearing factor and number of shears\n",
    "    out = np.identity(n)\n",
    "    \n",
    "    for ns in range(n_shears):\n",
    "        mat = np.identity(n)\n",
    "        i = np.random.randint(n)\n",
    "        j = np.random.randint(n-1)\n",
    "        if j>=i: j+=1\n",
    "        k = np.random.uniform(-max_shear, max_shear)\n",
    "        mat[i, j] = k\n",
    "        out = np.matmul(out, mat)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def gen_planes(n, x_min = 5, x_max = 20, shear = False, scale = False):\n",
    "    '''\n",
    "    generate a hypercube of constraints at random positive and negative coordinates defined by x_min and x_max\n",
    "    shear enables constraint shearing, scale enables constraint scaling\n",
    "    '''\n",
    "    coords = np.row_stack([\n",
    "        np.diag(np.random.uniform(x_min, x_max, size = n)),\n",
    "        -np.diag(np.random.uniform(x_min, x_max, size = n))])\n",
    "    \n",
    "    norms = coords\n",
    "    \n",
    "    if shear:\n",
    "        norms = np.matmul(norms, rand_shear_mat(n, n_shears = n//2))\n",
    "        \n",
    "    norms = norms / np.linalg.norm(norms, axis = -1)[:,np.newaxis]\n",
    "    \n",
    "    if scale:\n",
    "        norms = norms * np.power(10, np.random.uniform(0, 1, (2*n, 1)))\n",
    "        \n",
    "    return coords, norms\n",
    "\n",
    "\n",
    "def solve_planes(o, c, guess):\n",
    "    '''\n",
    "    Solve the hyperplanes problem analytically give objective coefficients o and contraint plane parameters c and \n",
    "    a guess vector of the solution location. Providing a guess avoids iterating over all possible corner combinatios\n",
    "    and massively speeds solution time.\n",
    "    ''' \n",
    "    n = len(o)\n",
    "    errors = Planes(*c)(guess).reshape(-1)\n",
    "    active = errors[:n] - errors[n:] > 0\n",
    "    mask = np.concatenate([active, ~active])\n",
    "    \n",
    "    b = np.sum(c[0][mask] * c[1][mask], axis = 1)\n",
    "    soln = np.linalg.solve(c[1][mask], b)\n",
    "    \n",
    "    return soln, np.dot(o, soln) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd483658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sphere:\n",
    "    '''\n",
    "    projection of input x onto hyperspherical coordinates via np.linalg.norm()\n",
    "    r_max specifies the radius of the spherical constraint.\n",
    "    '''\n",
    "    def __init__(self, r_max):\n",
    "        self.r_max = r_max\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return (np.linalg.norm(x, axis = 1) - self.r_max).reshape(1,-1)\n",
    "\n",
    "    \n",
    "def gen_sphere(r_min = 5, r_max = 20):\n",
    "    return np.random.uniform(r_min, r_max)\n",
    "\n",
    "\n",
    "def solve_sphere(o, r):\n",
    "    #Finds the true minimum of the the objective function subject to radial constraint r.\n",
    "    u = r / np.linalg.norm(o)\n",
    "    soln = -o*u\n",
    "    value = np.dot(o, soln)\n",
    "    \n",
    "    return soln, value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16825d53",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa22c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jacobian:\n",
    "    '''\n",
    "    Wrapper class that returns a second order estimate of the jacabian given step size for use with\n",
    "    scipy.optimize.minimum(jac = True)\n",
    "    '''\n",
    "    def __init__(self, problem, step = 1e-6):\n",
    "        self.problem = problem\n",
    "        self.step = step\n",
    "        \n",
    "        self.n = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if self.delta is None:\n",
    "            self.n = len(x)\n",
    "            self.delta = np.identity(self.n) * self.step / 2\n",
    "            self.delta = np.row_stack([np.zeros(self.n), self.delta, -self.delta])\n",
    "            self.n+=1\n",
    "\n",
    "        vals = self.problem(x + self.delta)\n",
    "        \n",
    "        return vals[0], (vals[1:self.n] - vals[self.n:]) / self.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(n, experiment_params, sphere = False, shear = False, const_scale = False, path = None):\n",
    "    #Run a constrained optimization experiment with n dimensions and specified parameters\n",
    "    \n",
    "    #A unique identifier for each experiment group\n",
    "    exp_id = secrets.token_hex(32)\n",
    "    \n",
    "    #select an random initial point\n",
    "    x0 = np.random.uniform(low = -250, high = 250, size = n)\n",
    "    \n",
    "    #select a random objecive and gradient\n",
    "    o_coeffs, grad = gen_objective(n, max_grad = 5)\n",
    "    \n",
    "    #generate and apply constraints\n",
    "    if sphere:\n",
    "        radius = gen_sphere()\n",
    "        projection = Sphere(radius)\n",
    "    else:\n",
    "        c_coeffs = gen_planes(n, x_min = 10, x_max = 25, shear = shear, scale = const_scale)\n",
    "        projection = Planes(*c_coeffs)\n",
    "    \n",
    "    #iterate over experimental groups, scaling paramters and hardness parameters, solving each optimization problem\n",
    "    exps = []\n",
    "    groups, combs, ptypes, sigmas, alphas, betas = [], [], [], [], [], []\n",
    "    for exp_group, params in experiment_params.items():\n",
    "        ptype = params['ptype']\n",
    "        beta = params['beta']\n",
    "        combine = params['combine']\n",
    "        for sigma in params['sigma']:\n",
    "            for alpha in params['alpha']:\n",
    "                prob = Problem(\n",
    "                    o_coeffs, \n",
    "                    projection,\n",
    "                    combine,\n",
    "                    ptype = ptype, \n",
    "                    sigma = sigma, \n",
    "                    alpha = alpha, \n",
    "                    beta = beta)\n",
    "                \n",
    "                prob_min = minimize(\n",
    "                    Jacobian(prob),\n",
    "                    x0,\n",
    "                    method = 'BFGS',\n",
    "                    jac = True\n",
    "                )\n",
    "                                                \n",
    "                groups.append(exp_group)\n",
    "                combs.append(combine)\n",
    "                ptypes.append(ptype)\n",
    "                sigmas.append(sigma)\n",
    "                alphas.append(alpha)\n",
    "                betas.append(beta)\n",
    "                \n",
    "                exps.append(prob_min)\n",
    "    \n",
    "    #find the true solution\n",
    "    if sphere:\n",
    "        solution, minval = solve_sphere(o_coeffs, radius)\n",
    "    else:\n",
    "        guess = np.median([e['x'] for e in exps], axis = 0)\n",
    "        solution, minval = solve_planes(o_coeffs, c_coeffs, guess)\n",
    "    \n",
    "    #store results\n",
    "    l = len(exps)\n",
    "    out = pd.DataFrame.from_dict({\n",
    "        'exp_id': [exp_id]*l,\n",
    "        'n_dims': [n]*l,\n",
    "        'grad': [grad]*l,\n",
    "        'sphere': [sphere]*l,\n",
    "        'shear': [shear]*l,\n",
    "        'const_scale': [const_scale]*l,\n",
    "        'group': groups,\n",
    "        'combine': combs,\n",
    "        'ptype': ptypes,\n",
    "        'sigma': sigmas,\n",
    "        'alpha': alphas,\n",
    "        'beta': betas,\n",
    "        'nfev':[e['nfev'] for e in exps],\n",
    "        'nit':[e['nit'] for e in exps],\n",
    "        'njev':[e['njev'] for e in exps],\n",
    "        'success':[e['success'] for e in exps],\n",
    "        'error':[np.linalg.norm(e['x'] - solution) for e in exps],\n",
    "    })\n",
    "    \n",
    "    if path is not None:\n",
    "        out.to_csv(f'{path}{exp_id}.csv')\n",
    "    \n",
    "    else: return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93093ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PickleableExp:\n",
    "    #Make experiments picklable so they can be processed with Pool.map()\n",
    "    def __init__(self, params, **kwargs):\n",
    "        self.params = params\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def __call__(self, n):\n",
    "        return experiment(n, self.params, **self.kwargs)\n",
    "\n",
    "def map_exps(tasks, params, **kwargs):\n",
    "    #map tasks to pickled experiemnts\n",
    "    exp = PickleableExp(params, **kwargs)\n",
    "    \n",
    "    with Pool(thread_count) as pool:\n",
    "        pool.map(exp, tasks)\n",
    "\n",
    "exp_kwargs = {\n",
    "    #'square':{'path':'./data/square_planes/'},\n",
    "    'shear':{'path':'./data/shear_planes/', 'shear':True},\n",
    "    #'scale':{'path':'./data/scale_planes/', 'const_scale':True},\n",
    "    #'shear_scale': {'path':'./data/shear_scale_planes/', 'shear':True, 'const_scale':True},\n",
    "    'sphere':{'path':'./data/spheres/', 'sphere':True},\n",
    "}\n",
    "\n",
    "\n",
    "for kwargs in exp_kwargs.values():\n",
    "    os.makedirs(kwargs['path'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tasks = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d85dbb",
   "metadata": {},
   "source": [
    "### Experiments 1 and 2\n",
    "Investigate performance of softplus and algebraic penalty functions on hyperplane and hypersphere problems with dimensions 2 - 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [2, 3, 5, 8, 12, 20, 32, 50] * n_tasks\n",
    "    \n",
    "experiment_params = {\n",
    "    'quadratic sum':{\n",
    "        'ptype': 'linear',\n",
    "        'sigma': [1e4],\n",
    "        'alpha': [0.0],\n",
    "        'beta': 2.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "    'algebraic norm':{\n",
    "        'ptype': 'algebraic',\n",
    "        'sigma': [15],\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algebraic sum':{\n",
    "        'ptype': 'algebraic',\n",
    "        'sigma': [15],\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "    'logistic norm':{\n",
    "        'ptype': 'logistic',\n",
    "        'sigma': [15],\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algx norm':{\n",
    "        'ptype': 'algx',\n",
    "        'sigma': [15],\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algx sum':{\n",
    "        'ptype': 'algx',\n",
    "        'sigma': [15],\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "}\n",
    "for key, kwargs in exp_kwargs.items():\n",
    "    print(key)\n",
    "    map_exps(tasks, experiment_params, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f37b54",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "Investigate sensitivity of penalty function error to scaling parameter sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [12] * n_tasks\n",
    "\n",
    "alpha_range = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "experiment_params = {\n",
    "    'algebraic norm':{\n",
    "        'ptype': 'algebraic',\n",
    "        'sigma': [15],\n",
    "        'alpha': alpha_range,\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algebraic sum':{\n",
    "        'ptype': 'algebraic',\n",
    "        'sigma': [15],\n",
    "        'alpha': alpha_range,\n",
    "        'beta': 1.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "    'logistic norm':{\n",
    "        'ptype': 'logistic',\n",
    "        'sigma': [15],\n",
    "        'alpha': alpha_range,\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algx norm':{\n",
    "        'ptype': 'algx',\n",
    "        'sigma': [15],\n",
    "        'alpha': alpha_range,\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algx sum':{\n",
    "        'ptype': 'algx',\n",
    "        'sigma': [15],\n",
    "        'alpha': alpha_range,\n",
    "        'beta': 1.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "}\n",
    "\n",
    "for key, kwargs in exp_kwargs.items():\n",
    "    print(key)\n",
    "    map_exps(tasks, experiment_params, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24395f16",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "Investigate sensitivity of penalty function error to hardness parameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_range = [1e1, 1e2, 1e4, 1e3, 1e5, 1e6, 1e7]\n",
    "\n",
    "experiment_params = {\n",
    "    'quadratic sum':{\n",
    "        'ptype': 'linear',\n",
    "        'sigma': sigma_range,\n",
    "        'alpha': [0.0],\n",
    "        'beta': 2.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "    'algebraic norm':{\n",
    "        'ptype': 'algebraic',\n",
    "        'sigma': sigma_range,\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algebraic sum':{\n",
    "        'ptype': 'algebraic',\n",
    "        'sigma': sigma_range,\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "    'logistic norm':{\n",
    "        'ptype': 'logistic',\n",
    "        'sigma': sigma_range,\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algx norm':{\n",
    "        'ptype': 'algx',\n",
    "        'sigma': sigma_range,\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'norm'\n",
    "    },\n",
    "    'algx sum':{\n",
    "        'ptype': 'algx',\n",
    "        'sigma': sigma_range,\n",
    "        'alpha': [3e-5],\n",
    "        'beta': 1.0,\n",
    "        'combine': 'sum'\n",
    "    },\n",
    "}\n",
    "\n",
    "for key, kwargs in exp_kwargs.items():\n",
    "    print(key)\n",
    "    map_exps(tasks, experiment_params, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
